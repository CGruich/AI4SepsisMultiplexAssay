{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc408f27",
   "metadata": {},
   "source": [
    "# Bayesian Optimize Training Region Classifier(s): Control Panel\n",
    "### Author: CG\n",
    "\n",
    "This notebook succeeds the \"train_particle_classifiers.ipynb\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee14e8",
   "metadata": {},
   "source": [
    "Here, we define a dictionary of input variables to initiate our particle detector training pipeline. This dictionary will be saved as a .json file and passed to the pipeline execution script, main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDict = {\n",
    "    \"sample_parent_directory\": \"/home/cameron/Dropbox (University of Michigan)/DL_training/data/classifier_training_samples/composite\",\n",
    "    # Where to save the timestamped model\n",
    "    \"model_save_parent_directory\": \"data/models/region\",\n",
    "    # Fraction of total training dataset to allocate as the test dataset for model predictive ability\n",
    "    \"test_size\": 0.20,\n",
    "    # Log via TensorBoard\n",
    "    \"log\": False,\n",
    "    # Printing verbosity\n",
    "    \"verbose\": False,\n",
    "    # Timestamp corresponding to this particular hyperparameter optimization run,\n",
    "    \"timestamp\": datetime.now().strftime(\"%m_%d_%y_%H:%M\"),\n",
    "    \"strat_kfold\": {\n",
    "        \"activate\": True,\n",
    "        # Num. of folds\n",
    "        \"num_folds\": 5,\n",
    "        # Controls the splitting of data in a reproducible way if the same seed is used\n",
    "        \"random_state\": 100,\n",
    "    },\n",
    "    # Save hyperparameter results every 'save_every' trials\n",
    "    \"save_every_n\": 1,\n",
    "    # Place to save checkpointed files\n",
    "    \"checkpoint_path\": \"hpo/region_classifier/multi/\",\n",
    "    # Number of hyperparameter trials to try\n",
    "    \"num_hpo\": 10,\n",
    "    # Time in seconds to wait before quitting each trial\n",
    "    \"timeout\": 600,\n",
    "    # How many epochs of no improvement to wait before stopping training run\n",
    "    \"patience\": 100,\n",
    "}\n",
    "\n",
    "# File save name\n",
    "inputJSON = \"bayesian_train_region_detector.json\"\n",
    "# Save\n",
    "with open(inputJSON, \"w\") as jsonFile:\n",
    "    json.dump(inputDict, jsonFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9cbd7a",
   "metadata": {},
   "source": [
    "## Train Particle Detectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0603d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.system(\n",
    "    f\"python main_cg_GPU.py --action bayesian_optimize_region_classifier --pipeline_inputs {inputJSON}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697e54b-fe8b-4609-9ffa-b1e21f5ccdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
