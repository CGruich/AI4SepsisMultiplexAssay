{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281a6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc408f27",
   "metadata": {},
   "source": [
    "# Bayesian Optimize Training Particle Classifier(s): Control Panel\n",
    "### Author: CG\n",
    "\n",
    "This notebook succeeds the \"train_particle_classifiers.ipynb\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee14e8",
   "metadata": {},
   "source": [
    "Here, we define a dictionary of input variables to initiate our particle detector training pipeline. This dictionary will be saved as a .json file and passed to the pipeline execution script, main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea25ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDict = {\n",
    "    \"sample_parent_directory\": \"/home/cameron/Dropbox (University of Michigan)/DL_training/data/classifier_training_samples\",\n",
    "    # Where to save the timestamped model\n",
    "    \"model_save_parent_directory\": \"data/models/code\",\n",
    "    # Specify codes to separately train the region detector on\n",
    "    # Must be in format \"(NUMBER)\" as per our experimental convention for naming codes\n",
    "    \"code_list\": [\"(1)\", \"(2)\", \"(3)\", \"(4)\", \"(5)\"],\n",
    "    # Fraction of total training dataset to allocate as the test dataset for model predictive ability\n",
    "    \"test_size\": 0.20,\n",
    "    # Log via TensorBoard\n",
    "    \"log\": False,\n",
    "    # Printing verbosity\n",
    "    \"verbose\": False,\n",
    "    # Timestamp corresponding to this particular hyperparameter optimization run,\n",
    "    \"timestamp\": datetime.now().strftime(\"%m_%d_%y_%H:%M\") + \"_production\",\n",
    "    \"strat_kfold\": {\n",
    "        \"activate\": True,\n",
    "        # Num. of folds\n",
    "        \"num_folds\": 5,\n",
    "        # Controls the splitting of data in a reproducible way if the same seed is used\n",
    "        \"random_state\": 100,\n",
    "        # Stratify by particle barcode stain level instead of just particle barcode\n",
    "        \"stratify_by_stain\": True,\n",
    "    },\n",
    "    # Save hyperparameter results every 'save_every' trials\n",
    "    \"save_every_n\": 2,\n",
    "    # Place to save checkpointed files\n",
    "    \"checkpoint_path\": \"hpo/code_classifier/multi/\",\n",
    "    # Load a pre-saved checkpoint to continue a study\n",
    "    # Defaults to None if no checkpoint is specified\n",
    "    \"checkpoint\": \"/home/cameron/Dropbox (University of Michigan)/DL_training/hpo/code_classifier/multi/11_29_23_13:25_production/ckpt_28.pkl\",\n",
    "    # Number of hyperparameter trials to try\n",
    "    \"num_hpo\": 60,\n",
    "    # Time in seconds to wait before the study\n",
    "    \"timeout\": None,\n",
    "    # How many epochs of no improvement to wait before stopping training run\n",
    "    \"patience\": 7500,\n",
    "    # How many epochs to wait before starting early-stopping\n",
    "    \"warmup\": 200,\n",
    "}\n",
    "\n",
    "# File save name\n",
    "inputJSON = \"bayesian_train_particle_detector.json\"\n",
    "# Save\n",
    "with open(inputJSON, \"w\") as jsonFile:\n",
    "    json.dump(inputDict, jsonFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9cbd7a",
   "metadata": {},
   "source": [
    "## Train Particle Detectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0603d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-01 13:20:32,548]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-12-01 13:46:08,950]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-12-01 16:02:35,595]\u001b[0m Trial 66 finished with value: 90.05678253173828 and parameters: {'learning_rate': 0.0005842286111605902, 'batch_size': 70, 'fully_connected_size': 768, 'fully_connected_layers': 4, 'dropout_rate': 0.03916046386715411, 'weight_decay': 0.018012548644386527}. Best is trial 18 with value: 99.09648284912109.\u001b[0m\n",
      "\u001b[32m[I 2023-12-01 16:48:02,563]\u001b[0m Trial 67 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-12-01 18:31:50,040]\u001b[0m Trial 68 finished with value: 94.77487335205078 and parameters: {'learning_rate': 0.0004729000142992684, 'batch_size': 100, 'fully_connected_size': 576, 'fully_connected_layers': 4, 'dropout_rate': 0.08733133143651839, 'weight_decay': 0.005572378271213985}. Best is trial 18 with value: 99.09648284912109.\u001b[0m\n",
      "\u001b[32m[I 2023-12-01 19:23:51,070]\u001b[0m Trial 69 finished with value: 79.71507415771484 and parameters: {'learning_rate': 0.0010212035365217624, 'batch_size': 180, 'fully_connected_size': 576, 'fully_connected_layers': 1, 'dropout_rate': 0.5868037184693272, 'weight_decay': 0.07549546189763623}. Best is trial 18 with value: 99.09648284912109.\u001b[0m\n",
      "\u001b[32m[I 2023-12-01 19:38:04,996]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-12-01 20:15:27,346]\u001b[0m Trial 71 pruned. \u001b[0m\n",
      "\u001b[33m[W 2023-12-01 20:20:45,404]\u001b[0m Trial 72 failed with parameters: {'learning_rate': 0.0024532149750918063, 'batch_size': 150, 'fully_connected_size': 704, 'fully_connected_layers': 4, 'dropout_rate': 0.5445847112713744, 'weight_decay': 0.023017868404428515} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/action_functions.py\", line 863, in objective_with_custom_input\n",
      "    return bayesian.objective_code_classifier(trial, pipeline_inputs)\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/bayesian.py\", line 31, in objective_code_classifier\n",
      "    cross_val_scores = action_functions.train_code_classifier(\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/action_functions.py\", line 810, in train_code_classifier\n",
      "    cross_val_scores = trainer.train(\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/code_classification_trainer_GPU.py\", line 220, in train\n",
      "    batches = self.generate_batches(train_data)\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/code_classification_trainer_GPU.py\", line 483, in generate_batches\n",
      "    single_image_pil = transforms.ToPILImage()(single_image)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 227, in __call__\n",
      "    return F.to_pil_image(pic, self.mode)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 334, in to_pil_image\n",
      "    return Image.fromarray(npimg, mode=mode)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/PIL/Image.py\", line 2945, in fromarray\n",
      "    ndim = len(shape)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-12-01 20:20:45,412]\u001b[0m Trial 72 failed with value None.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/main_cg_GPU.py\", line 42, in <module>\n",
      "    action_functions.bayesian_optimize_code_classifer(pipeline_inputs=pipeline_inputs)\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/action_functions.py\", line 865, in bayesian_optimize_code_classifer\n",
      "    study = bayesian.checkpoint_study(\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/bayesian.py\", line 85, in checkpoint_study\n",
      "    study.optimize(objective_function, n_trials=1)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/optuna/study/study.py\", line 425, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 251, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/action_functions.py\", line 863, in objective_with_custom_input\n",
      "    return bayesian.objective_code_classifier(trial, pipeline_inputs)\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/bayesian.py\", line 31, in objective_code_classifier\n",
      "    cross_val_scores = action_functions.train_code_classifier(\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/utils/action_functions.py\", line 810, in train_code_classifier\n",
      "    cross_val_scores = trainer.train(\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/code_classification_trainer_GPU.py\", line 220, in train\n",
      "    batches = self.generate_batches(train_data)\n",
      "  File \"/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/code_classification_trainer_GPU.py\", line 483, in generate_batches\n",
      "    single_image_pil = transforms.ToPILImage()(single_image)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 227, in __call__\n",
      "    return F.to_pil_image(pic, self.mode)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 334, in to_pil_image\n",
      "    return Image.fromarray(npimg, mode=mode)\n",
      "  File \"/home/cameron/Documents/envs/venv_cg_gpu/lib/python3.10/site-packages/PIL/Image.py\", line 2945, in fromarray\n",
      "    ndim = len(shape)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"python main_cg_GPU.py --action bayesian_optimize_code_classifier --pipeline_inputs {inputJSON}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
