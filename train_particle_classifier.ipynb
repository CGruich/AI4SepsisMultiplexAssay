{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc408f27",
   "metadata": {},
   "source": [
    "# Train Particle Classifier(s): Control Panel\n",
    "### Author: CG\n",
    "\n",
    "This notebook succeeds the \"train_region_classifiers.ipynb\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "281a6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee14e8",
   "metadata": {},
   "source": [
    "Here, we define a dictionary of input variables to initiate our particle detector training pipeline. This dictionary will be saved as a .json file and passed to the pipeline execution script, main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea25ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDict = {\"sample_parent_directory\": \"/home/cameron/Dropbox (University of Michigan)/DL_training/data/classifier_training_samples/composite\",\n",
    "             # Where to save the timestamped model\n",
    "             \"model_save_parent_directory\": \"data/models/code\",\n",
    "             # Specify codes to separately train the region detector on\n",
    "             # Must be in format \"(NUMBER)\" as per our experimental convention for naming codes\n",
    "             \"code_list\": [\"(1)\", \"(2)\", \"(3)\", \"(4)\", \"(5)\"],\n",
    "             #\"strat_kfold\": {\"activate\": True,\n",
    "             #                # Num. of folds\n",
    "             #                \"num_folds\": 5,\n",
    "             #                # Controls the splitting of data in a reproducible way if the same seed is used\n",
    "             #                \"random_state\": 100},\n",
    "             # Activates grid-search hyperparameter optimization if True\n",
    "             #\"grid_search_hpo\": {\"activate\": True,\n",
    "             #                    \"hpo_file\": \"/home/cameron/Dropbox (University of Michigan)/DL_training/hpo/region_classifier_grid_search/hpo_trials_region_classifier.csv\",\n",
    "             #                    # Save hyperparameter results every 'save_every' trials\n",
    "             #                    \"save_every\": 1,\n",
    "             #                    # Log via TensorBoard\n",
    "             #                    \"log\": True,\n",
    "             #                    # Timestamp corresponding to this particular hyperparameter optimization run,\n",
    "             #                    \"hpo_timestamp\": datetime.now().strftime(\"%m_%d_%y_%H:%M\"),\n",
    "             #                    # Printing verbosity\n",
    "             #                    \"verbose\": False},\n",
    "            }\n",
    "\n",
    "# File save name\n",
    "inputJSON = \"train_particle_detector.json\"\n",
    "# Save\n",
    "with open(inputJSON, \"w\") as jsonFile:\n",
    "    json.dump(inputDict, jsonFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9cbd7a",
   "metadata": {},
   "source": [
    "## Train Particle Detectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0603d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/code_classification_trainer_GPU.py:294: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.train_data = np.asarray(data[split:])\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/code_classification_trainer_GPU.py:295: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val_data = np.asarray(data[:split])\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/code_classification_trainer_GPU.py:302: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  self.val_data = (torch.as_tensor(v_regions, dtype=torch.float32), torch.as_tensor(v_labels, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"python main_cg_GPU.py --action train_code_classifier --pipeline_inputs {inputJSON}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6ab00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL_training-venv_cg_gpu] *",
   "language": "python",
   "name": "conda-env-DL_training-venv_cg_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
