{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc408f27",
   "metadata": {},
   "source": [
    "# Train Region Classifier(s): Control Panel\n",
    "### Author: CG\n",
    "\n",
    "This notebook succeeds the \"classify_regions_with_MSER.ipynb\" notebook and precedes the \"train_code_classifiers.ipynb\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "281a6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee14e8",
   "metadata": {},
   "source": [
    "Here, we define a dictionary of input variables to initiate our region detector training pipeline. This dictionary will be saved as a .json file and passed to the pipeline execution script, main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea25ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDict = {\n",
    "    \"sample_parent_directory\": \"/home/cameron/Dropbox (University of Michigan)/DL_training/data/classifier_training_samples/composite\",\n",
    "    # Where to save the timestamped model\n",
    "    \"model_save_parent_directory\": \"data/models/region\",\n",
    "    # Fraction of total dataset to allocate as the test dataset for model predictive ability\n",
    "    # This is fraction of the total dataset (train + val + test collectively), not fraction of the training dataset.\n",
    "    \"test_size\": 0.20,\n",
    "    # Log via TensorBoard\n",
    "    \"log\": True,\n",
    "    # Printing verbosity\n",
    "    \"verbose\": True,\n",
    "    # Timestamp corresponding to this particular hyperparameter optimization run,\n",
    "    \"timestamp\": datetime.now().strftime(\"%m_%d_%y_%H:%M\"),\n",
    "    \"strat_kfold\": {\n",
    "        \"activate\": True,\n",
    "        # Num. of folds, this splits the training dataset into num_folds, NOT the whole (train + val + test) dataset.\n",
    "        \"num_folds\": 2,\n",
    "        # Controls the splitting of data in a reproducible way if the same seed is used\n",
    "        \"random_state\": 100,\n",
    "        # Stratify by particle barcode stain level instead of just particle barcode\n",
    "        \"stratify_by_stain\": True,\n",
    "    },\n",
    "    # Save checkpointed version of model every n epochs\n",
    "    \"save_every_n\": 1000,\n",
    "    # Hyperparameters\n",
    "    # Batch Size\n",
    "    \"batch_size\": 448,\n",
    "    # Learning Rate\n",
    "    \"lr\": 0.00423027533208366,\n",
    "    # Adam Weight Decay\n",
    "    \"weight_decay\": 1e-3,\n",
    "    # Size of each fully-connected layer\n",
    "    \"fc_size\": 192,\n",
    "    # Number of fully-connected layers,\n",
    "    \"fc_num\": 5,\n",
    "    # Dropout rate to prevent overfitting\n",
    "    \"dropout_rate\": 0.026748827817905874,\n",
    "    # How many epochs of no improvement to wait before stopping training run\n",
    "    \"patience\": 100,\n",
    "    # How many epochs to wait before starting early-stopping\n",
    "    \"warmup\": 200,\n",
    "}\n",
    "\n",
    "\n",
    "# File save name\n",
    "inputJSON = \"train_region_detector.json\"\n",
    "# Save\n",
    "with open(inputJSON, \"w\") as jsonFile:\n",
    "    json.dump(inputDict, jsonFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9cbd7a",
   "metadata": {},
   "source": [
    "## Train Region Detectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd0603d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed Set: 100\n",
      "Loaded 1246 positive training samples.\n",
      "Loaded 1246 negative training samples.\n",
      "520 norm_stain_label_per_code_dict\n",
      "{'0': [], '1': []}\n",
      "524 norm_stain_label_per_code_dict\n",
      "{'0': [51, 373, 564, 605, 432, 309, 249, 609, 405, 501, 309, 120, 232, 441, 210, 481, 427, 104, 338, 145, 394, 582, 152, 572, 268, 576, 70, 390, 319, 317, 142, 515, 527, 260, 462, 528, 194, 376, 592, 585, 610, 387, 506, 230, 307, 34, 265, 395, 17, 87, 575, 518, 63, 129, 117, 438, 476, 5, 345, 114, 86, 65, 325, 161, 425, 375, 127, 171, 218, 48, 383, 254, 406, 9, 597, 468, 239, 242, 382, 167, 549, 318, 329, 183, 609, 190, 78, 499, 615, 446, 337, 391, 504, 92, 509, 110, 153, 533, 546, 418, 360, 605, 523, 34, 102, 262, 43, 333, 253, 542, 612, 387, 555, 251, 488, 33, 66, 357, 231, 614, 282, 14, 7, 554, 389, 375, 276, 113, 281, 489, 23, 568, 229, 163, 344, 396, 475, 521, 255, 541, 307, 426, 575, 274, 35, 225, 316, 505, 296, 55, 614, 366, 474, 470, 435, 559, 449, 497, 551, 476, 28, 116, 150, 427, 524, 553, 288, 258, 126, 350, 304, 567, 466, 489, 246, 305, 370, 59, 423, 436, 2, 269, 244, 130, 596, 578, 159, 405, 499, 75, 445, 455, 64, 200, 612, 176, 266, 542, 162, 553, 130, 491, 77, 333, 408, 47, 105, 564, 439, 430, 583, 37, 369, 93, 214, 24, 574, 155, 253, 552, 331, 617, 521, 154, 170, 482, 483, 96, 602, 136, 176, 151, 58, 294, 565, 263, 311, 0, 283, 465, 266, 560, 73, 56, 451, 295, 71, 420, 277, 101, 118, 274, 86, 163, 410, 95, 419, 203, 54, 146, 602, 178, 344, 175, 29, 187, 412, 437, 81, 301, 19, 61, 428, 438, 573, 111, 525, 289, 41, 613, 416, 337, 336, 312, 339, 398, 165, 292, 240, 440, 548, 268, 285, 71, 279, 464, 229, 54, 90, 125, 501, 495, 310, 169, 35, 13, 228, 587, 573, 536, 199, 424, 484, 107, 547, 362, 230, 223, 7, 460, 315, 393, 550, 119, 225, 11, 83, 62, 143, 224, 21, 15, 494, 102, 106, 211, 622, 453, 393, 522, 347, 161, 415, 259, 151, 120, 566, 47, 524, 495, 96, 611, 1, 220, 598, 534, 23, 472, 93, 182, 600, 74, 193, 159, 286, 607, 619, 334, 82, 586, 440, 294, 252, 115, 215, 220, 389, 118, 258, 267, 359, 166, 87, 552, 338, 115, 516, 526, 97, 447, 182, 29, 382, 261, 310, 498, 403, 206, 297, 593, 217, 160, 430, 36, 5, 520, 148, 164, 92, 203, 515, 68, 128, 55, 222, 205, 162, 352, 491, 278, 32, 409, 198, 482, 503, 315, 571, 317, 15, 168, 160, 518, 145, 131, 249, 519, 361, 332, 413, 620, 8, 467, 545, 218, 595, 555, 365, 277, 13, 584, 243, 296, 132, 411, 302, 363, 221, 135, 6, 101, 25, 76, 585, 532, 340, 67, 211, 570, 110, 392, 442, 370, 85, 475, 592, 272, 59, 615, 610, 415, 512, 462, 198, 60, 493, 488, 601, 185, 452, 44, 503, 523, 473, 53, 313, 535, 284, 84, 424, 541, 479, 275, 100, 502, 290, 150, 137, 80, 99, 57, 12, 3, 404, 416, 434, 85, 299, 112, 358, 144, 278, 10, 204, 263, 320, 244, 121, 554, 271, 404, 378, 422, 94, 313, 295, 618, 257, 547, 18, 202, 177, 18, 446, 109, 58, 397, 269, 526, 51, 285, 378, 500, 6, 68, 106, 452, 433, 303, 327, 180, 469, 543, 566, 534, 113, 544, 561, 335, 492, 104, 346, 20, 196, 413, 31, 177, 325, 591, 28, 353, 461, 509, 60, 40, 328, 400, 361, 330, 500, 539, 358, 187, 65, 46, 380, 477, 30, 454, 461, 132, 456, 259, 599, 364, 188, 127, 279, 52, 289, 371, 308, 346, 248, 348, 574, 41, 421, 0, 478, 287, 100, 64, 386, 331, 186, 557, 89, 580, 384, 385, 511, 384, 531, 301, 8, 411, 156, 544, 318, 390, 463, 329, 540, 175, 140, 376, 262, 388, 169, 178, 232, 621, 529, 172, 233, 565, 505, 79, 436, 199, 293, 522, 98, 195, 224, 606, 569, 399, 147, 517, 103, 39, 443, 207, 265, 350, 444, 607, 595, 433, 532, 326, 466, 107, 247, 364, 27, 243, 557, 401, 347, 280, 403, 179, 25, 402, 166, 460, 272, 248, 432, 228, 238, 326, 399, 386, 581, 559, 579, 124, 42, 487, 352, 567, 457, 576, 50, 380, 284, 133, 237, 257, 604, 621, 201, 617, 550, 577, 391, 543, 327, 398, 237, 290, 324, 247, 363, 507, 264, 73, 189, 563, 402, 483, 459, 171, 560, 234, 206, 89, 597, 593, 40, 456, 508, 264, 306, 131, 38, 467, 525, 31, 200, 409, 72, 339, 556, 167, 204, 292, 38, 32, 157, 77, 322, 12, 139, 396, 558, 245, 134, 209, 584, 383, 111, 140, 46, 80, 425, 304, 45, 435, 400, 116, 502, 52, 538, 146, 426, 368, 121, 108, 256, 184, 464, 410, 236, 506, 30, 471, 507, 250, 388, 546, 455, 50, 49, 342, 219, 453, 209, 303, 271, 239, 417, 528, 302, 69, 320, 545, 397, 270, 134, 494, 254, 321, 212, 354, 423, 349, 514, 88, 66, 168, 439, 437, 422, 538, 319, 135, 109, 298, 122, 558, 377, 207, 616, 508, 480, 14, 195, 589, 139, 323, 24, 471, 156, 16, 194, 286, 245, 17, 450, 581, 314, 231, 79, 465, 600, 39, 298, 441, 484, 570, 291, 537, 366, 75, 463, 305, 208, 283, 477, 62, 332, 138, 431, 267, 314, 108, 379, 91, 27, 616, 431, 362, 217, 105, 133, 613, 377, 74, 588, 561, 357, 342, 158, 61, 251, 216, 300, 479, 180, 235, 486, 76, 407, 442, 322, 472, 619, 11, 580, 330, 174, 587, 368, 487, 149, 336, 394, 122, 485, 252, 354, 451, 429, 306, 622, 594, 480, 193, 348, 572, 603, 2, 114, 154, 510, 192, 578, 136, 165, 490, 141, 201, 157, 141, 514, 583, 335, 504, 611, 128, 571, 234, 152, 493, 497, 589, 144, 450, 419, 447, 311, 420, 360, 212, 367, 490, 458, 510, 213, 608, 457, 138, 273, 548, 519, 125, 42, 149, 123, 213, 197, 164, 192, 147, 26, 22, 594, 444, 421, 406, 530, 321, 137, 90, 191, 215, 540, 57, 428, 214, 10, 235, 529, 197, 170, 568, 379, 288, 1, 49, 312, 468, 316, 255, 183, 174, 226, 372, 374, 98, 21, 112, 341, 356, 401, 618, 103, 43, 275, 88, 443, 240, 577, 448, 97, 381, 367, 236, 155, 22, 219, 148, 227, 190, 70, 458, 129, 300, 324, 385, 3, 19, 291, 158, 395, 16, 48, 345, 481, 242, 449, 533, 246, 26, 512, 516, 241, 191, 221, 143, 562, 4, 173, 588, 276, 119, 474, 179, 620, 470, 608, 353, 95, 485, 208, 334, 418, 205, 238, 603, 340, 414, 562, 496, 372, 520, 189, 473, 556, 530, 223, 33, 351, 604, 511, 341, 429, 261, 117, 579, 365, 124, 517, 527, 459, 599, 56, 414, 590, 486, 83, 531, 99, 355, 185, 496, 349, 596, 63, 343, 280, 256, 184, 478, 82, 586, 323, 328, 260, 297, 81, 369, 407, 381, 299, 417, 539, 222, 598, 590, 53, 606, 448, 355, 196, 172, 281, 293, 233, 549, 412, 78, 36, 569, 498, 513, 181, 551, 308, 371, 343, 373, 434, 392, 469, 126, 359, 188, 44, 9, 37, 591, 227, 173, 250, 91, 202, 142, 492, 181, 69, 20, 241, 563, 408, 535, 351, 356, 4, 445, 582, 536, 84, 67, 153, 374, 226, 123, 601, 513, 537, 72, 270, 282, 273, 216, 210, 94, 287, 186, 45, 454], '1': [430, 293, 446, 479, 588, 598, 48, 178, 9, 25, 365, 8, 353, 420, 398, 586, 235, 560, 309, 390, 219, 620, 301, 357, 256, 455, 541, 454, 421, 227, 412, 615, 161, 116, 388, 65, 358, 366, 563, 96, 546, 35, 143, 195, 418, 88, 107, 153, 31, 294, 565, 474, 312, 330, 208, 151, 484, 535, 594, 412, 154, 496, 18, 224, 46, 591, 499, 75, 114, 507, 389, 574, 80, 167, 562, 351, 228, 252, 140, 488, 600, 32, 450, 610, 391, 44, 218, 551, 501, 230, 11, 531, 143, 287, 553, 354, 110, 603, 487, 414, 480, 206, 587, 296, 314, 413, 310, 226, 216, 86, 104, 398, 500, 316, 288, 0, 55, 133, 570, 237, 170, 181, 609, 228, 408, 240, 302, 361, 293, 241, 436, 116, 284, 123, 606, 579, 604, 33, 455, 76, 514, 129, 569, 391, 172, 323, 494, 448, 104, 168, 88, 340, 569, 435, 185, 530, 70, 134, 332, 106, 533, 64, 100, 410, 402, 26, 205, 296, 126, 16, 473, 313, 485, 557, 292, 23, 284, 356, 620, 465, 248, 71, 79, 238, 300, 239, 43, 128, 418, 476, 484, 271, 117, 301, 357, 416, 48, 593, 64, 381, 93, 619, 515, 405, 584, 467, 8, 539, 364, 603, 342, 328, 453, 450, 451, 460, 419, 495, 34, 151, 456, 604, 614, 124, 597, 608, 380, 128, 555, 169, 454, 307, 567, 312, 258, 537, 329, 101, 91, 169, 397, 42, 191, 543, 578, 361, 519, 401, 564, 191, 119, 205, 164, 179, 614, 197, 7, 394, 379, 10, 194, 399, 106, 276, 285, 577, 30, 66, 131, 289, 63, 388, 524, 496, 452, 263, 571, 213, 115, 294, 327, 522, 490, 582, 466, 68, 274, 200, 431, 573, 492, 416, 415, 237, 505, 386, 87, 207, 85, 7, 152, 69, 363, 320, 239, 343, 334, 109, 557, 195, 9, 166, 287, 19, 386, 318, 437, 124, 127, 520, 13, 521, 185, 281, 321, 443, 127, 147, 415, 253, 283, 160, 281, 348, 270, 170, 97, 433, 506, 182, 375, 324, 615, 426, 58, 59, 60, 174, 103, 177, 218, 453, 105, 462, 328, 534, 49, 96, 302, 194, 369, 263, 599, 282, 610, 286, 559, 417, 537, 3, 349, 468, 299, 187, 267, 356, 591, 115, 346, 139, 405, 517, 232, 315, 425, 510, 177, 531, 401, 76, 491, 305, 212, 515, 372, 265, 150, 474, 157, 125, 31, 427, 539, 272, 250, 273, 289, 53, 544, 297, 265, 203, 393, 36, 449, 403, 186, 229, 236, 467, 479, 527, 213, 146, 463, 58, 350, 410, 271, 149, 322, 172, 555, 38, 618, 422, 279, 189, 344, 222, 563, 425, 580, 566, 561, 327, 578, 503, 442, 464, 337, 378, 130, 511, 159, 126, 538, 94, 273, 210, 334, 290, 536, 55, 485, 90, 10, 308, 438, 597, 584, 122, 59, 553, 433, 3, 568, 402, 369, 424, 184, 219, 342, 370, 544, 478, 80, 325, 89, 236, 123, 439, 54, 223, 102, 491, 274, 204, 142, 260, 529, 609, 585, 347, 4, 72, 253, 617, 44, 97, 363, 329, 411, 493, 36, 121, 443, 50, 67, 403, 536, 95, 556, 490, 178, 365, 34, 545, 440, 117, 396, 462, 428, 434, 576, 93, 540, 441, 214, 470, 201, 70, 280, 138, 598, 136, 51, 2, 534, 231, 461, 82, 202, 221, 335, 85, 590, 171, 324, 314, 250, 592, 188, 404, 78, 183, 158, 291, 39, 456, 83, 259, 477, 341, 332, 565, 19, 611, 461, 278, 612, 49, 249, 590, 152, 460, 74, 220, 254, 364, 320, 423, 234, 202, 394, 176, 545, 535, 524, 585, 400, 432, 326, 567, 574, 298, 600, 477, 157, 345, 212, 83, 558, 526, 582, 0, 568, 487, 326, 571, 201, 429, 345, 86, 622, 482, 279, 15, 186, 277, 45, 120, 547, 303, 112, 442, 135, 581, 280, 190, 362, 560, 111, 18, 161, 427, 87, 4, 216, 233, 241, 113, 406, 447, 375, 159, 112, 247, 458, 374, 278, 333, 225, 516, 227, 495, 612, 331, 589, 367, 39, 523, 67, 208, 505, 255, 583, 428, 550, 362, 162, 384, 12, 95, 211, 118, 299, 459, 251, 17, 444, 136, 27, 605, 550, 183, 47, 132, 541, 56, 452, 392, 133, 507, 20, 134, 348, 165, 607, 424, 360, 523, 463, 257, 147, 53, 243, 209, 20, 249, 367, 577, 240, 113, 269, 146, 317, 592, 174, 532, 142, 503, 619, 17, 92, 27, 75, 5, 404, 189, 244, 344, 244, 99, 338, 622, 168, 137, 291, 209, 436, 419, 94, 311, 245, 513, 264, 72, 2, 561, 125, 235, 131, 204, 165, 148, 81, 121, 525, 264, 211, 222, 217, 377, 206, 188, 489, 517, 573, 6, 163, 580, 368, 549, 114, 351, 43, 599, 82, 449, 90, 506, 266, 6, 193, 616, 28, 417, 54, 431, 483, 518, 576, 145, 472, 383, 464, 336, 387, 595, 540, 307, 423, 78, 360, 322, 277, 354, 141, 382, 429, 420, 290, 465, 538, 180, 79, 61, 91, 215, 23, 575, 21, 164, 572, 371, 304, 179, 502, 262, 268, 552, 153, 306, 16, 525, 285, 62, 608, 26, 434, 184, 374, 492, 435, 245, 42, 145, 383, 283, 319, 621, 256, 350, 140, 57, 166, 234, 305, 62, 508, 481, 352, 144, 257, 548, 366, 532, 339, 393, 547, 472, 313, 432, 330, 513, 41, 335, 37, 119, 255, 343, 596, 71, 458, 118, 459, 353, 512, 148, 101, 316, 566, 137, 210, 308, 379, 543, 319, 522, 242, 527, 25, 466, 444, 340, 182, 57, 259, 248, 270, 298, 193, 40, 310, 171, 469, 414, 510, 441, 63, 355, 102, 129, 69, 509, 500, 200, 317, 520, 579, 426, 601, 359, 47, 526, 68, 173, 1, 203, 40, 309, 376, 468, 269, 611, 469, 399, 407, 606, 438, 470, 11, 199, 355, 160, 421, 89, 448, 499, 231, 13, 14, 546, 30, 445, 621, 73, 504, 586, 141, 323, 37, 494, 223, 359, 358, 529, 385, 196, 594, 254, 497, 315, 613, 549, 471, 542, 498, 238, 84, 207, 84, 382, 368, 100, 144, 511, 149, 66, 331, 528, 156, 392, 409, 138, 339, 217, 347, 605, 175, 214, 192, 389, 230, 486, 275, 24, 120, 488, 548, 337, 583, 276, 349, 552, 190, 501, 162, 616, 286, 430, 29, 303, 251, 413, 528, 12, 266, 33, 601, 516, 509, 406, 21, 99, 52, 260, 295, 224, 267, 498, 98, 409, 596, 451, 192, 198, 376, 475, 92, 74, 400, 132, 508, 77, 73, 341, 476, 28, 321, 155, 595, 587, 173, 261, 29, 575, 14, 81, 411, 60, 570, 46, 282, 233, 593, 247, 5, 52, 175, 377, 504, 122, 297, 589, 618, 325, 473, 272, 396, 372, 422, 295, 371, 373, 554, 607, 457, 108, 613, 108, 407, 292, 352, 311, 440, 150, 486, 275, 50, 542, 181, 512, 242, 447, 338, 478, 196, 41, 617, 300, 318, 556, 77, 22, 370, 387, 530, 489, 156, 481, 384, 564, 130, 602, 226, 154, 110, 385, 306, 139, 199, 480, 559, 304, 158, 246, 346, 243, 103, 135, 471, 483, 497, 602, 521, 65, 32, 56, 562, 288, 1, 533, 163, 22, 554, 220, 519, 221, 98, 35, 268, 45, 378, 395, 493, 232, 38, 215, 558, 437, 258, 167, 439, 588, 261, 180, 105, 61, 333, 446, 197, 408, 381, 15, 572, 111, 445, 457, 252, 380, 187, 24, 51, 395, 373, 514, 336, 581, 109, 229, 198, 475, 262, 482, 390, 176, 107, 502, 551, 397, 246, 225, 518, 155]}\n",
      "        0\n",
      "0      51\n",
      "1     373\n",
      "2     564\n",
      "3     605\n",
      "4     432\n",
      "...   ...\n",
      "1241   94\n",
      "1242  287\n",
      "1243  186\n",
      "1244   45\n",
      "1245  454\n",
      "\n",
      "[1246 rows x 1 columns]\n",
      "        0\n",
      "0     430\n",
      "1     293\n",
      "2     446\n",
      "3     479\n",
      "4     588\n",
      "...   ...\n",
      "1241  397\n",
      "1242  246\n",
      "1243  225\n",
      "1244  518\n",
      "1245  155\n",
      "\n",
      "[1246 rows x 1 columns]\n",
      "[[array([[[0.91224537, 0.94042878, 0.94512856, ..., 0.90577554,\n",
      "           0.93702602, 0.90782025],\n",
      "          [0.9319295 , 0.91567864, 0.9145037 , ..., 0.89941253,\n",
      "           0.94779889, 0.91168078],\n",
      "          [0.92579538, 0.92306401, 0.92399481, ..., 0.92198062,\n",
      "           0.94471656, 0.96299687],\n",
      "          ...,\n",
      "          [0.93858244, 0.91859312, 0.87614252, ..., 0.91847105,\n",
      "           0.91094835, 0.93112078],\n",
      "          [0.93325704, 0.91616693, 0.92187381, ..., 0.90614176,\n",
      "           0.94505226, 0.90804913],\n",
      "          [0.92863355, 0.81422141, 0.84429694, ..., 0.91342031,\n",
      "           0.90897993, 0.94023041]]])                           '1_142']\n",
      " [array([[[0.98486305, 0.95028611, 0.99264515, ..., 0.93054093,\n",
      "           0.99775692, 0.96029603],\n",
      "          [0.98075837, 0.92666514, 0.94901961, ..., 0.96954299,\n",
      "           0.99482719, 0.95588617],\n",
      "          [1.        , 0.96708629, 1.        , ..., 0.95713741,\n",
      "           0.95619135, 0.98475624],\n",
      "          ...,\n",
      "          [0.91358816, 0.89132525, 0.91671626, ..., 0.935729  ,\n",
      "           0.97338827, 0.97701991],\n",
      "          [0.91248951, 0.85610742, 0.89773404, ..., 0.98709087,\n",
      "           1.        , 0.99008164],\n",
      "          [0.98506142, 0.95533684, 0.90087739, ..., 0.96694896,\n",
      "           0.95039292, 0.95802243]]])                           '1_97']\n",
      " [array([[[0.97938506, 1.        , 0.96055543, ..., 0.96298161,\n",
      "           0.96020447, 0.99298085],\n",
      "          [0.96945144, 0.98556497, 0.93929961, ..., 0.91963073,\n",
      "           0.95051499, 0.95617609],\n",
      "          [0.9943389 , 1.        , 0.96835279, ..., 0.99337758,\n",
      "           0.95420768, 0.9722591 ],\n",
      "          ...,\n",
      "          [0.94865339, 0.99005112, 0.92632944, ..., 0.93719387,\n",
      "           0.94196994, 0.95556573],\n",
      "          [0.98391699, 0.98059052, 1.        , ..., 0.97053483,\n",
      "           0.95648127, 1.        ],\n",
      "          [0.96575875, 0.97314412, 0.93493553, ..., 0.98324559,\n",
      "           0.98843366, 0.97605859]]])                           '1_148']\n",
      " ...\n",
      " [array([[[0.95486381, 0.96244755, 0.94914168, ..., 0.97097734,\n",
      "           0.94390784, 0.95844968],\n",
      "          [0.93920806, 0.92835889, 0.9373312 , ..., 0.95121691,\n",
      "           0.96343938, 0.95890745],\n",
      "          [0.90009918, 0.92458991, 0.92942702, ..., 0.99861143,\n",
      "           0.96498054, 0.9400473 ],\n",
      "          ...,\n",
      "          [0.93000687, 0.91285573, 0.92632944, ..., 0.91456474,\n",
      "           0.86965743, 0.88592355],\n",
      "          [0.93751431, 0.94135958, 0.92159915, ..., 0.98840314,\n",
      "           0.96124208, 0.95709163],\n",
      "          [0.95306325, 0.90897993, 0.92201114, ..., 0.96864271,\n",
      "           0.95718318, 0.96232547]]])                           '0_61']\n",
      " [array([[[0.9647364 , 0.91958495, 0.89571984, ..., 0.99476616,\n",
      "           1.        , 0.99380484],\n",
      "          [0.93760586, 0.89150835, 0.87821775, ..., 0.96464485,\n",
      "           0.98355077, 1.        ],\n",
      "          [0.97196918, 0.88447395, 0.84875257, ..., 0.9859617 ,\n",
      "           0.96479744, 0.9531548 ],\n",
      "          ...,\n",
      "          [0.97582971, 0.96742199, 0.952224  , ..., 0.88722057,\n",
      "           0.90011444, 0.95019455],\n",
      "          [0.9272755 , 0.94528115, 0.96835279, ..., 0.91917296,\n",
      "           0.93502708, 1.        ],\n",
      "          [0.95082017, 0.99455253, 0.97727932, ..., 0.9223621 ,\n",
      "           1.        , 1.        ]]])                           '0_14']\n",
      " [array([[[1.        , 1.        , 1.        , ..., 0.99172961,\n",
      "           0.95240711, 0.90424964],\n",
      "          [1.        , 1.        , 1.        , ..., 0.93685817,\n",
      "           0.89507897, 0.90345617],\n",
      "          [1.        , 1.        , 1.        , ..., 0.93263142,\n",
      "           0.91525139, 0.93875029],\n",
      "          ...,\n",
      "          [1.        , 1.        , 1.        , ..., 0.99296559,\n",
      "           0.98193332, 0.97282368],\n",
      "          [1.        , 1.        , 1.        , ..., 0.92886244,\n",
      "           0.96379034, 0.95178149],\n",
      "          [1.        , 1.        , 1.        , ..., 1.        ,\n",
      "           0.95300221, 0.9840238 ]]])                           '0_150']]\n",
      "\n",
      "\n",
      "Fold 1\n",
      "CUDA Availability: True\n",
      "\n",
      "Region Classifier Model Architecture:\n",
      "RegionClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(1, 32, kernel_size=(6, 6), stride=(3, 3))\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (6): PReLU(num_parameters=1)\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Linear(in_features=256, out_features=192, bias=True)\n",
      "    (11): PReLU(num_parameters=1)\n",
      "    (12): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (13): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (15): PReLU(num_parameters=1)\n",
      "    (16): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (17): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (19): PReLU(num_parameters=1)\n",
      "    (20): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (21): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (23): PReLU(num_parameters=1)\n",
      "    (24): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (25): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (27): PReLU(num_parameters=1)\n",
      "    (28): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (29): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): Linear(in_features=192, out_features=2, bias=True)\n",
      "    (31): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (32): Softmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Model Loaded to GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 1:: 100%|██████████| 2/2 [00:00<00:00, 48.21it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(50.05015182495117, 49.89979934692383, 0)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:: 100%|██████████| 2/2 [00:00<00:00, 48.12it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 3:: 100%|██████████| 2/2 [00:00<00:00, 44.54it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 4:: 100%|██████████| 2/2 [00:00<00:00, 50.19it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 5:: 100%|██████████| 2/2 [00:00<00:00, 50.85it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 6:: 100%|██████████| 2/2 [00:00<00:00, 49.31it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 7:: 100%|██████████| 2/2 [00:00<00:00, 51.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(50.25075149536133, 50.10020065307617, 7)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(50.45135498046875, 50.10020065307617, 8)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(52.557674407958984, 51.30260467529297, 9)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:: 100%|██████████| 2/2 [00:00<00:00, 50.62it/s]\n",
      "Epoch 9:: 100%|██████████| 2/2 [00:00<00:00, 46.83it/s]\n",
      "Epoch 10:: 100%|██████████| 2/2 [00:00<00:00, 50.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(55.0651969909668, 54.50901794433594, 10)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(59.679039001464844, 58.51703643798828, 11)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(64.89468383789062, 63.12625503540039, 12)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11:: 100%|██████████| 2/2 [00:00<00:00, 49.18it/s]\n",
      "Epoch 12:: 100%|██████████| 2/2 [00:00<00:00, 50.33it/s]\n",
      "Epoch 13:: 100%|██████████| 2/2 [00:00<00:00, 50.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(75.52658081054688, 73.9478988647461, 13)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(88.5656967163086, 87.9759521484375, 14)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(97.99398040771484, 97.5951919555664, 15)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:: 100%|██████████| 2/2 [00:00<00:00, 50.37it/s]\n",
      "Epoch 15:: 100%|██████████| 2/2 [00:00<00:00, 50.47it/s]\n",
      "Epoch 16:: 100%|██████████| 2/2 [00:00<00:00, 44.10it/s]\n",
      "Epoch 17:: 100%|██████████| 2/2 [00:00<00:00, 48.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.29789733886719, 98.99799346923828, 16)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.49849700927734, 99.59919738769531, 17)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18:: 100%|██████████| 2/2 [00:00<00:00, 48.20it/s]\n",
      "Epoch 19:: 100%|██████████| 2/2 [00:00<00:00, 48.07it/s]\n",
      "Epoch 20:: 100%|██████████| 2/2 [00:00<00:00, 50.01it/s]\n",
      "Epoch 21:: 100%|██████████| 2/2 [00:00<00:00, 47.48it/s]\n",
      "Epoch 22:: 100%|██████████| 2/2 [00:00<00:00, 50.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.6990966796875, 99.79959869384766, 21)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23:: 100%|██████████| 2/2 [00:00<00:00, 46.21it/s]\n",
      "Epoch 24:: 100%|██████████| 2/2 [00:00<00:00, 45.81it/s]\n",
      "Epoch 25:: 100%|██████████| 2/2 [00:00<00:00, 49.76it/s]\n",
      "Epoch 26:: 100%|██████████| 2/2 [00:00<00:00, 50.31it/s]\n",
      "Epoch 27:: 100%|██████████| 2/2 [00:00<00:00, 50.46it/s]\n",
      "Epoch 28::   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.79940032958984, 100.0, 26)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28:: 100%|██████████| 2/2 [00:00<00:00, 47.45it/s]\n",
      "Epoch 29:: 100%|██████████| 2/2 [00:00<00:00, 51.14it/s]\n",
      "Epoch 30:: 100%|██████████| 2/2 [00:00<00:00, 50.39it/s]\n",
      "Epoch 31:: 100%|██████████| 2/2 [00:00<00:00, 49.84it/s]\n",
      "Epoch 32:: 100%|██████████| 2/2 [00:00<00:00, 48.39it/s]\n",
      "Epoch 33:: 100%|██████████| 2/2 [00:00<00:00, 51.62it/s]\n",
      "Epoch 34:: 100%|██████████| 2/2 [00:00<00:00, 52.05it/s]\n",
      "Epoch 35:: 100%|██████████| 2/2 [00:00<00:00, 53.11it/s]\n",
      "Epoch 36:: 100%|██████████| 2/2 [00:00<00:00, 51.39it/s]\n",
      "Epoch 37:: 100%|██████████| 2/2 [00:00<00:00, 48.26it/s]\n",
      "Epoch 38:: 100%|██████████| 2/2 [00:00<00:00, 50.06it/s]\n",
      "Epoch 39:: 100%|██████████| 2/2 [00:00<00:00, 51.12it/s]\n",
      "Epoch 40:: 100%|██████████| 2/2 [00:00<00:00, 49.88it/s]\n",
      "Epoch 41:: 100%|██████████| 2/2 [00:00<00:00, 50.55it/s]\n",
      "Epoch 42:: 100%|██████████| 2/2 [00:00<00:00, 50.31it/s]\n",
      "Epoch 43:: 100%|██████████| 2/2 [00:00<00:00, 47.75it/s]\n",
      "Epoch 44:: 100%|██████████| 2/2 [00:00<00:00, 50.74it/s]\n",
      "Epoch 45:: 100%|██████████| 2/2 [00:00<00:00, 50.64it/s]\n",
      "Epoch 46:: 100%|██████████| 2/2 [00:00<00:00, 51.38it/s]\n",
      "Epoch 47:: 100%|██████████| 2/2 [00:00<00:00, 45.91it/s]\n",
      "Epoch 48:: 100%|██████████| 2/2 [00:00<00:00, 52.24it/s]\n",
      "Epoch 49:: 100%|██████████| 2/2 [00:00<00:00, 50.72it/s]\n",
      "Epoch 50:: 100%|██████████| 2/2 [00:00<00:00, 50.64it/s]\n",
      "Epoch 51:: 100%|██████████| 2/2 [00:00<00:00, 51.04it/s]\n",
      "Epoch 52:: 100%|██████████| 2/2 [00:00<00:00, 48.73it/s]\n",
      "Epoch 53:: 100%|██████████| 2/2 [00:00<00:00, 51.32it/s]\n",
      "Epoch 54:: 100%|██████████| 2/2 [00:00<00:00, 48.87it/s]\n",
      "Epoch 55:: 100%|██████████| 2/2 [00:00<00:00, 49.87it/s]\n",
      "Epoch 56:: 100%|██████████| 2/2 [00:00<00:00, 49.40it/s]\n",
      "Epoch 57:: 100%|██████████| 2/2 [00:00<00:00, 52.28it/s]\n",
      "Epoch 58:: 100%|██████████| 2/2 [00:00<00:00, 51.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.89969635009766, 100.0, 57)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_1/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59:: 100%|██████████| 2/2 [00:00<00:00, 51.50it/s]\n",
      "Epoch 60:: 100%|██████████| 2/2 [00:00<00:00, 52.75it/s]\n",
      "Epoch 61:: 100%|██████████| 2/2 [00:00<00:00, 51.36it/s]\n",
      "Epoch 62:: 100%|██████████| 2/2 [00:00<00:00, 51.10it/s]\n",
      "Epoch 63:: 100%|██████████| 2/2 [00:00<00:00, 52.52it/s]\n",
      "Epoch 64:: 100%|██████████| 2/2 [00:00<00:00, 49.20it/s]\n",
      "Epoch 65:: 100%|██████████| 2/2 [00:00<00:00, 42.91it/s]\n",
      "Epoch 66:: 100%|██████████| 2/2 [00:00<00:00, 51.36it/s]\n",
      "Epoch 67:: 100%|██████████| 2/2 [00:00<00:00, 52.19it/s]\n",
      "Epoch 68:: 100%|██████████| 2/2 [00:00<00:00, 51.77it/s]\n",
      "Epoch 69:: 100%|██████████| 2/2 [00:00<00:00, 50.93it/s]\n",
      "Epoch 70:: 100%|██████████| 2/2 [00:00<00:00, 49.90it/s]\n",
      "Epoch 71:: 100%|██████████| 2/2 [00:00<00:00, 50.88it/s]\n",
      "Epoch 72:: 100%|██████████| 2/2 [00:00<00:00, 51.62it/s]\n",
      "Epoch 73:: 100%|██████████| 2/2 [00:00<00:00, 50.12it/s]\n",
      "Epoch 74:: 100%|██████████| 2/2 [00:00<00:00, 50.45it/s]\n",
      "Epoch 75:: 100%|██████████| 2/2 [00:00<00:00, 49.95it/s]\n",
      "Epoch 76:: 100%|██████████| 2/2 [00:00<00:00, 50.89it/s]\n",
      "Epoch 77:: 100%|██████████| 2/2 [00:00<00:00, 51.85it/s]\n",
      "Epoch 78:: 100%|██████████| 2/2 [00:00<00:00, 49.36it/s]\n",
      "Epoch 79:: 100%|██████████| 2/2 [00:00<00:00, 51.69it/s]\n",
      "Epoch 80:: 100%|██████████| 2/2 [00:00<00:00, 53.04it/s]\n",
      "Epoch 81:: 100%|██████████| 2/2 [00:00<00:00, 51.52it/s]\n",
      "Epoch 82:: 100%|██████████| 2/2 [00:00<00:00, 49.19it/s]\n",
      "Epoch 83:: 100%|██████████| 2/2 [00:00<00:00, 49.15it/s]\n",
      "Epoch 84:: 100%|██████████| 2/2 [00:00<00:00, 43.89it/s]\n",
      "Epoch 85:: 100%|██████████| 2/2 [00:00<00:00, 51.97it/s]\n",
      "Epoch 86:: 100%|██████████| 2/2 [00:00<00:00, 52.65it/s]\n",
      "Epoch 87:: 100%|██████████| 2/2 [00:00<00:00, 51.86it/s]\n",
      "Epoch 88:: 100%|██████████| 2/2 [00:00<00:00, 50.82it/s]\n",
      "Epoch 89:: 100%|██████████| 2/2 [00:00<00:00, 51.20it/s]\n",
      "Epoch 90:: 100%|██████████| 2/2 [00:00<00:00, 52.82it/s]\n",
      "Epoch 91:: 100%|██████████| 2/2 [00:00<00:00, 49.12it/s]\n",
      "Epoch 92:: 100%|██████████| 2/2 [00:00<00:00, 51.00it/s]\n",
      "Epoch 93:: 100%|██████████| 2/2 [00:00<00:00, 47.31it/s]\n",
      "Epoch 94:: 100%|██████████| 2/2 [00:00<00:00, 43.54it/s]\n",
      "Epoch 95:: 100%|██████████| 2/2 [00:00<00:00, 52.05it/s]\n",
      "Epoch 96:: 100%|██████████| 2/2 [00:00<00:00, 52.21it/s]\n",
      "Epoch 97:: 100%|██████████| 2/2 [00:00<00:00, 51.52it/s]\n",
      "Epoch 98:: 100%|██████████| 2/2 [00:00<00:00, 49.55it/s]\n",
      "Epoch 99:: 100%|██████████| 2/2 [00:00<00:00, 47.01it/s]\n",
      "Epoch 100:: 100%|██████████| 2/2 [00:00<00:00, 51.58it/s]\n",
      "Epoch 101:: 100%|██████████| 2/2 [00:00<00:00, 50.18it/s]\n",
      "Epoch 102:: 100%|██████████| 2/2 [00:00<00:00, 50.22it/s]\n",
      "Epoch 103:: 100%|██████████| 2/2 [00:00<00:00, 50.16it/s]\n",
      "Epoch 104:: 100%|██████████| 2/2 [00:00<00:00, 50.75it/s]\n",
      "Epoch 105:: 100%|██████████| 2/2 [00:00<00:00, 45.29it/s]\n",
      "Epoch 106:: 100%|██████████| 2/2 [00:00<00:00, 51.31it/s]\n",
      "Epoch 107:: 100%|██████████| 2/2 [00:00<00:00, 52.02it/s]\n",
      "Epoch 108:: 100%|██████████| 2/2 [00:00<00:00, 50.22it/s]\n",
      "Epoch 109:: 100%|██████████| 2/2 [00:00<00:00, 50.47it/s]\n",
      "Epoch 110:: 100%|██████████| 2/2 [00:00<00:00, 52.51it/s]\n",
      "Epoch 111:: 100%|██████████| 2/2 [00:00<00:00, 51.59it/s]\n",
      "Epoch 112:: 100%|██████████| 2/2 [00:00<00:00, 51.44it/s]\n",
      "Epoch 113:: 100%|██████████| 2/2 [00:00<00:00, 47.07it/s]\n",
      "Epoch 114:: 100%|██████████| 2/2 [00:00<00:00, 50.35it/s]\n",
      "Epoch 115:: 100%|██████████| 2/2 [00:00<00:00, 46.31it/s]\n",
      "Epoch 0:: 100%|██████████| 2/2 [00:00<00:00, 50.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fold 2\n",
      "CUDA Availability: True\n",
      "\n",
      "Region Classifier Model Architecture:\n",
      "RegionClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(1, 32, kernel_size=(6, 6), stride=(3, 3))\n",
      "    (2): PReLU(num_parameters=1)\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (6): PReLU(num_parameters=1)\n",
      "    (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Linear(in_features=256, out_features=192, bias=True)\n",
      "    (11): PReLU(num_parameters=1)\n",
      "    (12): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (13): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (15): PReLU(num_parameters=1)\n",
      "    (16): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (17): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (19): PReLU(num_parameters=1)\n",
      "    (20): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (21): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (23): PReLU(num_parameters=1)\n",
      "    (24): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (25): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): Linear(in_features=192, out_features=192, bias=True)\n",
      "    (27): PReLU(num_parameters=1)\n",
      "    (28): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (29): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): Linear(in_features=192, out_features=2, bias=True)\n",
      "    (31): Dropout(p=0.026748827817905874, inplace=False)\n",
      "    (32): Softmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Model Loaded to GPU: True\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.3975830078125, 99.59919738769531, 0)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_2/checkpoints\n",
      "data/models/region/11_30_23_23:53/fold_2/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:: 100%|██████████| 2/2 [00:00<00:00, 50.32it/s]\n",
      "Epoch 2:: 100%|██████████| 2/2 [00:00<00:00, 52.26it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 3:: 100%|██████████| 2/2 [00:00<00:00, 50.77it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 4:: 100%|██████████| 2/2 [00:00<00:00, 46.92it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 5:: 100%|██████████| 2/2 [00:00<00:00, 50.38it/s]\n",
      "/home/cameron/Dropbox (University of Michigan)/DL_training/model_training/region_classification_trainer_GPU.py:499: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
      "Epoch 6:: 100%|██████████| 2/2 [00:00<00:00, 51.28it/s]\n",
      "Epoch 7:: 100%|██████████| 2/2 [00:00<00:00, 50.45it/s]\n",
      "Epoch 8:: 100%|██████████| 2/2 [00:00<00:00, 52.11it/s]\n",
      "Epoch 9:: 100%|██████████| 2/2 [00:00<00:00, 49.54it/s]\n",
      "Epoch 10:: 100%|██████████| 2/2 [00:00<00:00, 49.82it/s]\n",
      "Epoch 11:: 100%|██████████| 2/2 [00:00<00:00, 48.42it/s]\n",
      "Epoch 12:: 100%|██████████| 2/2 [00:00<00:00, 50.61it/s]\n",
      "Epoch 13:: 100%|██████████| 2/2 [00:00<00:00, 49.75it/s]\n",
      "Epoch 14:: 100%|██████████| 2/2 [00:00<00:00, 50.54it/s]\n",
      "Epoch 15:: 100%|██████████| 2/2 [00:00<00:00, 52.13it/s]\n",
      "Epoch 16:: 100%|██████████| 2/2 [00:00<00:00, 49.34it/s]\n",
      "Epoch 17:: 100%|██████████| 2/2 [00:00<00:00, 48.95it/s]\n",
      "Epoch 18:: 100%|██████████| 2/2 [00:00<00:00, 50.41it/s]\n",
      "Epoch 19::   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.49798583984375, 99.59919738769531, 16)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_2/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.69879150390625, 99.59919738769531, 17)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_2/checkpoints\n",
      "(New Best Val. Acc., Correspond. Test Acc., Epoch):\n",
      "(99.89959716796875, 99.79959869384766, 18)\n",
      "\n",
      "data/models/region/11_30_23_23:53/fold_2/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19:: 100%|██████████| 2/2 [00:00<00:00, 48.85it/s]\n",
      "Epoch 20:: 100%|██████████| 2/2 [00:00<00:00, 51.03it/s]\n",
      "Epoch 21:: 100%|██████████| 2/2 [00:00<00:00, 50.86it/s]\n",
      "Epoch 22:: 100%|██████████| 2/2 [00:00<00:00, 50.31it/s]\n",
      "Epoch 23:: 100%|██████████| 2/2 [00:00<00:00, 51.01it/s]\n",
      "Epoch 24:: 100%|██████████| 2/2 [00:00<00:00, 50.49it/s]\n",
      "Epoch 25:: 100%|██████████| 2/2 [00:00<00:00, 51.65it/s]\n",
      "Epoch 26:: 100%|██████████| 2/2 [00:00<00:00, 51.61it/s]\n",
      "Epoch 27:: 100%|██████████| 2/2 [00:00<00:00, 48.64it/s]\n",
      "Epoch 28:: 100%|██████████| 2/2 [00:00<00:00, 50.54it/s]\n",
      "Epoch 29:: 100%|██████████| 2/2 [00:00<00:00, 49.40it/s]\n",
      "Epoch 30:: 100%|██████████| 2/2 [00:00<00:00, 51.59it/s]\n",
      "Epoch 31:: 100%|██████████| 2/2 [00:00<00:00, 50.55it/s]\n",
      "Epoch 32:: 100%|██████████| 2/2 [00:00<00:00, 50.99it/s]\n",
      "Epoch 33:: 100%|██████████| 2/2 [00:00<00:00, 51.67it/s]\n",
      "Epoch 34:: 100%|██████████| 2/2 [00:00<00:00, 50.04it/s]\n",
      "Epoch 35:: 100%|██████████| 2/2 [00:00<00:00, 45.09it/s]\n",
      "Epoch 36:: 100%|██████████| 2/2 [00:00<00:00, 51.34it/s]\n",
      "Epoch 37:: 100%|██████████| 2/2 [00:00<00:00, 48.37it/s]\n",
      "Epoch 38:: 100%|██████████| 2/2 [00:00<00:00, 50.63it/s]\n",
      "Epoch 39:: 100%|██████████| 2/2 [00:00<00:00, 48.58it/s]\n",
      "Epoch 40:: 100%|██████████| 2/2 [00:00<00:00, 49.00it/s]\n",
      "Epoch 41:: 100%|██████████| 2/2 [00:00<00:00, 51.28it/s]\n",
      "Epoch 42:: 100%|██████████| 2/2 [00:00<00:00, 51.16it/s]\n",
      "Epoch 43:: 100%|██████████| 2/2 [00:00<00:00, 51.86it/s]\n",
      "Epoch 44:: 100%|██████████| 2/2 [00:00<00:00, 47.82it/s]\n",
      "Epoch 45:: 100%|██████████| 2/2 [00:00<00:00, 50.95it/s]\n",
      "Epoch 46:: 100%|██████████| 2/2 [00:00<00:00, 51.16it/s]\n",
      "Epoch 47:: 100%|██████████| 2/2 [00:00<00:00, 52.86it/s]\n",
      "Epoch 48:: 100%|██████████| 2/2 [00:00<00:00, 48.99it/s]\n",
      "Epoch 49:: 100%|██████████| 2/2 [00:00<00:00, 50.25it/s]\n",
      "Epoch 50:: 100%|██████████| 2/2 [00:00<00:00, 49.30it/s]\n",
      "Epoch 51:: 100%|██████████| 2/2 [00:00<00:00, 49.74it/s]\n",
      "Epoch 52:: 100%|██████████| 2/2 [00:00<00:00, 48.47it/s]\n",
      "Epoch 53:: 100%|██████████| 2/2 [00:00<00:00, 50.15it/s]\n",
      "Epoch 54:: 100%|██████████| 2/2 [00:00<00:00, 50.46it/s]\n",
      "Epoch 55:: 100%|██████████| 2/2 [00:00<00:00, 49.49it/s]\n",
      "Epoch 56:: 100%|██████████| 2/2 [00:00<00:00, 50.88it/s]\n",
      "Epoch 57:: 100%|██████████| 2/2 [00:00<00:00, 50.00it/s]\n",
      "Epoch 58:: 100%|██████████| 2/2 [00:00<00:00, 51.65it/s]\n",
      "Epoch 59:: 100%|██████████| 2/2 [00:00<00:00, 50.26it/s]\n",
      "Epoch 60:: 100%|██████████| 2/2 [00:00<00:00, 48.20it/s]\n",
      "Epoch 61:: 100%|██████████| 2/2 [00:00<00:00, 49.73it/s]\n",
      "Epoch 62:: 100%|██████████| 2/2 [00:00<00:00, 49.71it/s]\n",
      "Epoch 63:: 100%|██████████| 2/2 [00:00<00:00, 49.93it/s]\n",
      "Epoch 64:: 100%|██████████| 2/2 [00:00<00:00, 50.36it/s]\n",
      "Epoch 65:: 100%|██████████| 2/2 [00:00<00:00, 45.45it/s]\n",
      "Epoch 66:: 100%|██████████| 2/2 [00:00<00:00, 52.49it/s]\n",
      "Epoch 67:: 100%|██████████| 2/2 [00:00<00:00, 51.39it/s]\n",
      "Epoch 68:: 100%|██████████| 2/2 [00:00<00:00, 49.81it/s]\n",
      "Epoch 69:: 100%|██████████| 2/2 [00:00<00:00, 50.90it/s]\n",
      "Epoch 70:: 100%|██████████| 2/2 [00:00<00:00, 46.04it/s]\n",
      "Epoch 71:: 100%|██████████| 2/2 [00:00<00:00, 50.56it/s]\n",
      "Epoch 72:: 100%|██████████| 2/2 [00:00<00:00, 50.49it/s]\n",
      "Epoch 73:: 100%|██████████| 2/2 [00:00<00:00, 46.58it/s]\n",
      "Epoch 74:: 100%|██████████| 2/2 [00:00<00:00, 49.85it/s]\n",
      "Epoch 75:: 100%|██████████| 2/2 [00:00<00:00, 50.59it/s]\n",
      "Epoch 76:: 100%|██████████| 2/2 [00:00<00:00, 47.64it/s]\n",
      "Epoch 77:: 100%|██████████| 2/2 [00:00<00:00, 50.41it/s]\n",
      "Epoch 78:: 100%|██████████| 2/2 [00:00<00:00, 51.39it/s]\n",
      "Epoch 79:: 100%|██████████| 2/2 [00:00<00:00, 48.64it/s]\n",
      "Epoch 80:: 100%|██████████| 2/2 [00:00<00:00, 51.76it/s]\n",
      "Epoch 81:: 100%|██████████| 2/2 [00:00<00:00, 52.28it/s]\n",
      "Epoch 82:: 100%|██████████| 2/2 [00:00<00:00, 50.54it/s]\n",
      "Epoch 83:: 100%|██████████| 2/2 [00:00<00:00, 47.82it/s]\n",
      "Epoch 84:: 100%|██████████| 2/2 [00:00<00:00, 50.47it/s]\n",
      "Epoch 85:: 100%|██████████| 2/2 [00:00<00:00, 51.21it/s]\n",
      "Epoch 86:: 100%|██████████| 2/2 [00:00<00:00, 51.31it/s]\n",
      "Epoch 87:: 100%|██████████| 2/2 [00:00<00:00, 50.24it/s]\n",
      "Epoch 88:: 100%|██████████| 2/2 [00:00<00:00, 50.51it/s]\n",
      "Epoch 89:: 100%|██████████| 2/2 [00:00<00:00, 51.31it/s]\n",
      "Epoch 90:: 100%|██████████| 2/2 [00:00<00:00, 50.89it/s]\n",
      "Epoch 91:: 100%|██████████| 2/2 [00:00<00:00, 48.78it/s]\n",
      "Epoch 92:: 100%|██████████| 2/2 [00:00<00:00, 51.94it/s]\n",
      "Epoch 93:: 100%|██████████| 2/2 [00:00<00:00, 52.81it/s]\n",
      "Epoch 94:: 100%|██████████| 2/2 [00:00<00:00, 51.73it/s]\n",
      "Epoch 95:: 100%|██████████| 2/2 [00:00<00:00, 51.01it/s]\n",
      "Epoch 96:: 100%|██████████| 2/2 [00:00<00:00, 51.11it/s]\n",
      "Epoch 97:: 100%|██████████| 2/2 [00:00<00:00, 48.81it/s]\n",
      "Epoch 98:: 100%|██████████| 2/2 [00:00<00:00, 50.08it/s]\n",
      "Epoch 99:: 100%|██████████| 2/2 [00:00<00:00, 52.58it/s]\n",
      "Epoch 100:: 100%|██████████| 2/2 [00:00<00:00, 49.00it/s]\n",
      "Epoch 101:: 100%|██████████| 2/2 [00:00<00:00, 50.33it/s]\n",
      "Epoch 102:: 100%|██████████| 2/2 [00:00<00:00, 51.78it/s]\n",
      "Epoch 103:: 100%|██████████| 2/2 [00:00<00:00, 51.46it/s]\n",
      "Epoch 104:: 100%|██████████| 2/2 [00:00<00:00, 51.56it/s]\n",
      "Epoch 105:: 100%|██████████| 2/2 [00:00<00:00, 51.44it/s]\n",
      "Epoch 106:: 100%|██████████| 2/2 [00:00<00:00, 48.56it/s]\n",
      "Epoch 107:: 100%|██████████| 2/2 [00:00<00:00, 52.14it/s]\n",
      "Epoch 108:: 100%|██████████| 2/2 [00:00<00:00, 52.62it/s]\n",
      "Epoch 109:: 100%|██████████| 2/2 [00:00<00:00, 49.67it/s]\n",
      "Epoch 110:: 100%|██████████| 2/2 [00:00<00:00, 50.60it/s]\n",
      "Epoch 111:: 100%|██████████| 2/2 [00:00<00:00, 50.43it/s]\n",
      "Epoch 112:: 100%|██████████| 2/2 [00:00<00:00, 51.08it/s]\n",
      "Epoch 113:: 100%|██████████| 2/2 [00:00<00:00, 47.07it/s]\n",
      "Epoch 114:: 100%|██████████| 2/2 [00:00<00:00, 46.67it/s]\n",
      "Epoch 115:: 100%|██████████| 2/2 [00:00<00:00, 48.69it/s]\n",
      "Epoch 116:: 100%|██████████| 2/2 [00:00<00:00, 49.04it/s]\n",
      "Epoch 117:: 100%|██████████| 2/2 [00:00<00:00, 49.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING COMPLETE.\n",
      "Cross-Validation Dictionary:\n",
      "{'Val_Loss': [0.06736479699611664, 0.015311064198613167], 'Val_Acc': [99.89969635009766, 99.89959716796875], 'Test_Loss': [0.07766761630773544, 0.012669461779296398], 'Test_Acc': [100.0, 99.79959869384766]}\n",
      "Avg. Val_Loss: 0.0413379305973649\n",
      "Avg. Val_Acc: 99.8996467590332\n",
      "Avg. Test_Loss: 0.04516853904351592\n",
      "Avg. Test_Acc: 99.89979934692383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\n",
    "    f\"python main_cg_GPU.py --action train_region_classifier --pipeline_inputs {inputJSON}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07815ac0-791f-4e11-96ef-6c057186b7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
